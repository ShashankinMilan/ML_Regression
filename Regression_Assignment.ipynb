{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slkXux_B1lxV"
      },
      "source": [
        "# **Importing the needed Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK8MS7PU09FY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3Kt2fMi2Tes"
      },
      "source": [
        "# **Reading the File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe9lFElb2gYs"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('model_1.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "_5h2LnVsFx5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "f5M5_Fg6F__K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bOO2VZttVL6"
      },
      "outputs": [],
      "source": [
        "#converting the categorical value to the numerical value\n",
        "df['product_category'].replace({\"business\": 1, \"cleaning\": 2, \"entertainment\": 3, \"other\": 4, \"sport\": 5, \"tech\": 6, \"travel\": 7},inplace=True)\n",
        "df['day'].replace({\"monday\":1,\"tuesday\":2, \"wednesday\": 3, \"thursday\": 4, \"friday\": 5, \"saturday\": 6, \"sunday\": 7},inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a3t2_s6P9ng"
      },
      "source": [
        "# **Visualizing the Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NVWAGQcZU1p"
      },
      "source": [
        "**Visualizing the data with likes less than 10000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hL6ac9luIrV"
      },
      "outputs": [],
      "source": [
        "df1 = df[df['likes'] < 10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVos8lZoOHlk"
      },
      "outputs": [],
      "source": [
        "#Using the pairplot to understand the relationship of target variables with various variables\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.pairplot(df1, y_vars = 'likes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9-GW-dEUVI3"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df1['likes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoNf_LTJZKVI"
      },
      "outputs": [],
      "source": [
        "#Visualizing the correlation using a heatmap\n",
        "plt.figure(figsize=(30, 30))\n",
        "sns.heatmap(data= df1.corr().round(2), cmap = 'coolwarm', linewidths = .5, annot = True, annot_kws ={\"size\":12})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwvEWTrsQYFV"
      },
      "source": [
        "**Visualizing the data with likes greater than 10000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z0ztOOacCg2"
      },
      "outputs": [],
      "source": [
        "df2 = df[df['likes'] > 10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-S6IZE6CQrPa"
      },
      "outputs": [],
      "source": [
        "#Using the pairplot to understand the relationship of target variables with various variables\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.pairplot(df2, y_vars = 'likes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0ZztgeTQ_X3"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df2['likes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwEJ7tpxQx1T"
      },
      "outputs": [],
      "source": [
        "#Visualizing the correlation using a heatmap\n",
        "plt.figure(figsize=(30, 30))\n",
        "sns.heatmap(data= df2.corr().round(2), cmap = 'coolwarm', linewidths = .5, annot = True, annot_kws ={\"size\":12})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to understand the relationship of 14 variables with the target value\n",
        "New_df= df[[\"num_hrefs\", \"num_imgs\", \"num_keywords\", \" self_reference_min_shares\", \" self_reference_max_shares\", \" self_reference_avg_sharess\", \"day\", \"topic_quality\", \"topic_description\", \"topic_others\", \" n_non_stop_unique_tokens\", \"topic_shipping\", \"topic_packaging\",\"product_category\"]]\n",
        "New_df.hist(figsize=(10,10))"
      ],
      "metadata": {
        "id": "ruGAAqSIIs5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df\n",
        "import math\n",
        "df3['likes2']=df3['likes'].apply(lambda x: math.log(x+1))\n",
        "df3['num_hrefs2']=df3['num_hrefs'].apply(lambda x: math.log(x+1))\n",
        "df3['nnum_imgs2']=df3['num_imgs'].apply(lambda x: math.log(x+1))\n",
        "df4= df3[[\"num_hrefs\", \"num_imgs\", \"num_keywords\", \" self_reference_min_shares\", \" self_reference_max_shares\", \" self_reference_avg_sharess\", \"day\", \"topic_quality\", \"topic_description\", \"topic_others\", \" n_non_stop_unique_tokens\", \"topic_shipping\", \"topic_packaging\",\"product_category\", \"likes\"]]\n",
        "plt.figure(figsize=(30, 30))\n",
        "sns.heatmap(data= df4.corr().round(2), cmap = 'coolwarm', linewidths = .5, annot = True, annot_kws ={\"size\":12})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ebs8bIjCJKqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6lBPzc5njBg"
      },
      "outputs": [],
      "source": [
        "#creating the test train split\n",
        "\n",
        "df5 = df\n",
        "from sklearn.model_selection import train_test_split\n",
        "#14 selected variable as an independent variable\n",
        "X= df5[[\"num_hrefs\", \"num_imgs\", \"num_keywords\", \" self_reference_min_shares\", \" self_reference_max_shares\", \" self_reference_avg_sharess\", \"day\", \"topic_quality\", \"topic_description\", \"topic_others\", \" n_non_stop_unique_tokens\", \"topic_shipping\", \"topic_packaging\",\"product_category\"]]\n",
        "#conversion of y to comparable log values\n",
        "Y= df5['likes'].apply(lambda x: math.log(x+1))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=42)\n",
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Models For Regression**"
      ],
      "metadata": {
        "id": "wVUbzsdkLKFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import math\n",
        "\n",
        "def gs_regression(model, par) :\n",
        "    gs = GridSearchCV(model, par,cv=3,scoring ='neg_mean_absolute_error')\n",
        "    gs = gs.fit(X_train,y_train)\n",
        "\n",
        "    #summarizing the GRIDSEARCH RESULTS\n",
        "    print('***GRIDSEARCH RESULTS***')\n",
        "    print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
        "    means = gs.cv_results_['mean_test_score']\n",
        "    stds = gs.cv_results_['std_test_score']\n",
        "    params = gs.cv_results_['params']\n",
        "\n",
        "\n",
        "    y_pred_train=gs.predict(X_train)\n",
        "    y_pred_test=gs.predict(X_test)\n",
        "    #conversion of y value to original value\n",
        "    y_train_exp=y_train.apply(lambda x: math.exp(x)-1)\n",
        "    y_test_exp=y_test.apply(lambda x: math.exp(x)-1)\n",
        "    y_pred_train_exp=np.exp(y_pred_train)-1\n",
        "    y_pred_test_exp=np.exp(y_pred_test)-1\n",
        "\n",
        "\n",
        "    from sklearn import metrics\n",
        "    print()\n",
        "    print(\"MAE  train %.3f (%f)  test %.3f (%f)\" % (metrics.mean_absolute_error(y_train, y_pred_train), metrics.mean_absolute_error(y_train_exp, y_pred_train_exp) ,metrics.mean_absolute_error(y_test, y_pred_test),  metrics.mean_absolute_error(y_test_exp, y_pred_test_exp)  ) )\n",
        "    print(\"MSE  train %.3f              test %.3f\" % (metrics.mean_squared_error(y_train, y_pred_train), metrics.mean_squared_error(y_test, y_pred_test)) )\n",
        "    print(\"RMSE train %.3f              test %.3f\" % (np.sqrt(metrics.mean_squared_error(y_train, y_pred_train)), np.sqrt(metrics.mean_squared_error(y_test, y_pred_test))) )\n",
        "    print(\"r2   train %.3f              test %.3f\" % (metrics.r2_score(y_train, y_pred_train), metrics.r2_score(y_test, y_pred_test)) )"
      ],
      "metadata": {
        "id": "V-urhy75LUVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "regressor = LinearRegression()\n",
        "parameters = {}\n",
        "\n",
        "gs_regression(regressor, parameters)"
      ],
      "metadata": {
        "id": "pc36Cq-TLv2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ridge Regression\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "regressor = Ridge()\n",
        "parameters = {\"alpha\": [0.001,0.01,0.1,1,10], \"normalize\": [True, False]}\n",
        "\n",
        "gs_regression(regressor, parameters)"
      ],
      "metadata": {
        "id": "ZV7shWCDMBaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lasso Regression\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "regressor = Lasso()\n",
        "parameters = {\"alpha\": [0.001,0.01,0.1,1,10], \"normalize\": [True, False]}\n",
        "\n",
        "gs_regression(regressor, parameters)"
      ],
      "metadata": {
        "id": "HP0VciqmMOmf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN Regressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "regressor = KNeighborsRegressor()\n",
        "\n",
        "parameters = {'n_neighbors': np.arange(20,50,10),\n",
        "              'p': [1,2]\n",
        "            }\n",
        "\n",
        "gs_regression(regressor, parameters)"
      ],
      "metadata": {
        "id": "1U7z4MQRMYiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree Regressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "regressor = DecisionTreeRegressor()\n",
        "parameters = {\"max_depth\": np.arange(1,5),\n",
        "              \"min_samples_leaf\": np.arange(1,5)}\n",
        "\n",
        "gs_regression(regressor, parameters)\n"
      ],
      "metadata": {
        "id": "D_GyrQ7HMcHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RandomForest Regressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "regressor = RandomForestRegressor()\n",
        "parameters = {\"n_estimators\":[10,50, 100,200], \"criterion\": ['mse'],\n",
        "              \"min_samples_leaf\": [0.07, 1.0, 0.3], \"random_state\" : [42]}\n",
        "\n",
        "gs_regression(regressor, parameters)\n"
      ],
      "metadata": {
        "id": "U4XQweEJMsbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Selection**"
      ],
      "metadata": {
        "id": "12H_cxmSSvgf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxdA5x0Epn36"
      },
      "outputs": [],
      "source": [
        "#We have selected the KNN Regressor as predictive model\n",
        "x= df[[\"num_hrefs\", \"num_imgs\", \"num_keywords\", \" self_reference_min_shares\", \" self_reference_max_shares\", \" self_reference_avg_sharess\", \"day\", \"topic_quality\", \"topic_description\", \"topic_others\", \" n_non_stop_unique_tokens\", \"topic_shipping\", \"topic_packaging\",\"product_category\"]]\n",
        "Y= df.iloc[:, -1]\n",
        "y = Y.apply(lambda x: math.log(x+1))\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "regressor = KNeighborsRegressor()\n",
        "\n",
        "parameters = {'n_neighbors': np.arange(20,50,10),\n",
        "              'p': [1,2]\n",
        "            }\n",
        "\n",
        "#gs_regression(regressor, parameters)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "KNN = GridSearchCV(regressor, parameters, cv=3)\n",
        "\n",
        "KNN.fit(x,Y)\n",
        "\n",
        "y_pred=KNN.predict(x)\n",
        "error=Y-y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(y_pred,error, c=\"b\", label=\"training data\")\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.hlines(y=0, xmin=0, xmax=8, color=\"r\")\n",
        "plt.xlim([0,8])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5_YtkD0ID3Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "nb_error = np.array(error).flatten()\n",
        "\n",
        "error = np.array(error).reshape(-1,1)\n",
        "scaled_error= StandardScaler(copy=False).fit(error).transform(error).flatten()"
      ],
      "metadata": {
        "id": "LEK5J39tjCD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.graphics.gofplots import qqplot_2samples\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "dist = getattr(scipy.stats, 'norm')\n",
        "param = dist.fit(nb_error)\n",
        "\n",
        "err_mean=param[-2]\n",
        "err_std=param[-1]\n",
        "\n",
        "test_dist = dist.rvs(*param[0:-2],loc=param[-2], scale=param[-1])\n",
        "\n",
        "ax = sns.histplot(nb_error, stat='density')\n",
        "\n",
        "# calculating the pdf\n",
        "x0, x1 = ax.get_xlim()\n",
        "x_pdf = np.linspace(x0, x1, 100)\n",
        "y_pdf = scipy.stats.norm.pdf(x_pdf, loc=err_mean, scale=err_std)\n"
      ],
      "metadata": {
        "id": "TPKRdDHBjh16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(KNN, open('KNN_model.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "XfO50MZs6GBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p = pd.read_csv('predictions.csv')"
      ],
      "metadata": {
        "id": "-ZV70WAU5VJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p['product_category'].replace({\"business\": 1, \"cleaning\": 2, \"entertainment\": 3, \"other\": 4, \"sport\": 5, \"tech\": 6, \"travel\": 7},inplace=True)\n",
        "df_p['day'].replace({\"monday\":1,\"tuesday\":2, \"wednesday\": 3, \"thursday\": 4, \"friday\": 5, \"saturday\": 6, \"sunday\": 7},inplace=True)\n",
        "\n",
        "X2= df_p[[\"num_hrefs\", \"num_imgs\", \"num_keywords\", \" self_reference_min_shares\", \" self_reference_max_shares\", \" self_reference_avg_sharess\", \"day\", \"topic_quality\", \"topic_description\", \"topic_others\", \" n_non_stop_unique_tokens\", \"topic_shipping\", \"topic_packaging\",\"product_category\"]]\n"
      ],
      "metadata": {
        "id": "e5_DKDaH5bVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "loaded_model = pickle.load(open('KNN_model.pkl', 'rb'))\n",
        "\n",
        "#model.fit(X_train,y_train)\n",
        "# we could retrain with the entire dataset\n",
        "\n",
        "y2_predictions=loaded_model.predict(X2)"
      ],
      "metadata": {
        "id": "MiO4PP1B5e8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y2_predictions)"
      ],
      "metadata": {
        "id": "25lB2RET9lmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(y2_predictions).to_csv(\"values.csv\")"
      ],
      "metadata": {
        "id": "KD24rAWj_Yhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y2_pred=np.exp(y2_predictions)-1\n",
        "print(y2_pred)\n",
        "pd.DataFrame(y2_pred).to_csv(\"values2.csv\")"
      ],
      "metadata": {
        "id": "fbSy8ZnZ98sc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}